{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tibame_UsefulLinks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVAYFcwfokLw"
      },
      "source": [
        "# **Data Mining**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQo3EgU2mggO"
      },
      "source": [
        "**Pandas 輸出到 JSON 的說明**\n",
        "\n",
        "https://datatofish.com/export-pandas-dataframe-json/\n",
        "\n",
        "**Pandas Merge/Join/Concat 的不同在哪？**\n",
        "\n",
        "https://towardsdatascience.com/3-key-differences-between-merge-and-concat-functions-of-pandas-ab2bab224b59\n",
        "\n",
        "**EDA 更多的例子from kaggle**\n",
        "\n",
        "https://www.kaggle.com/dejavu23/house-prices-eda-to-ml-beginner\n",
        "\n",
        "https://www.kaggle.com/dejavu23/titanic-eda-to-ml-beginner\n",
        "\n",
        "https://www.kaggle.com/meetdoshi996/melbourne-housing-snapshot-eda/comments\n",
        "\n",
        "\n",
        "**關聯規則分析 Apriori 演算法說明**\n",
        "\n",
        "https://medium.com/marketingdatascience/%E4%BD%A0%E6%80%8E%E9%BA%BC%E8%99%95%E7%90%86%E9%A1%A7%E5%AE%A2%E4%BA%A4%E6%98%93%E8%B3%87%E8%A8%8A-apriori%E6%BC%94%E7%AE%97%E6%B3%95-1523b1f8443b\n",
        "\n",
        "**關聯規則分析 FP-Growth 演算法**\n",
        "\n",
        "https://www.itread01.com/content/1546888205.html\n",
        "\n",
        "**Linear Reression 展示**\n",
        "\n",
        "https://www.desmos.com/calculator/jwquvmikhr?lang=zh-CN\n",
        "\n",
        "**Logistic Regression 展示**\n",
        "\n",
        "https://www.desmos.com/calculator/naf1qogfjn?lang=zh-CN\n",
        "\n",
        "**Label Encoding/One Hot Encoding：如何轉換類別型變數到數值型**\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/\n",
        "\n",
        "**Normalization：如何調整資料大小(Scaling)**\n",
        "\n",
        "https://www.codecademy.com/articles/normalization#:~:text=Min%2Dmax%20normalization%20is%20one,decimal%20between%200%20and%201.&text=That%20data%20is%20just%20as%20squished%20as%20before!\n",
        "\n",
        "**Covariance and Correlation：相關係數是標準化的協方差**\n",
        "\n",
        "https://www.mygreatlearning.com/blog/covariance-vs-correlation/#:~:text=Covariance%20is%20nothing%20but%20a,linear%20relationship%20between%20two%20variables.\n",
        "\n",
        "**K-means 動態展示**\n",
        "\n",
        "https://stanford.edu/class/engr108/visualizations/kmeans/kmeans.html\n",
        "\n",
        "**不同種類變數間的關係數計算**\n",
        "\n",
        "1.數值變數和數值變數的相關係數：Pearson Corelation Coefficient\n",
        "\n",
        "2.數值變數和類別變數的相關係數：Chi-Squared or Cramer's V：Chi-Squared or Cramer's V\n",
        "\n",
        "https://www.statology.org/cramers-v-in-python/\n",
        "\n",
        "3.類別變數和類別變數的相關係數: Eta Squared,or Anova\n",
        "\n",
        "https://dzone.com/articles/correlation-between-categorical-and-continuous-var-1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYIOawp9qWc2"
      },
      "source": [
        "# **Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1pUkizbqdFX"
      },
      "source": [
        "**Linear Regression 成立的 假設**\n",
        "\n",
        "https://www.yongxi-stat.com/simple-regression-analysis/\n",
        "\n",
        "https://www.statology.org/linear-regression-assumptions/\n",
        "\n",
        "**fit(), transform(), fit_transform() and predict()**\n",
        "\n",
        "https://www.linkedin.com/pulse/difference-between-fit-transform-fittransform-predict-aman-agarwal/\n",
        "\n",
        "**Linear Regression 與 Logistic Regression**\n",
        "\n",
        "https://www.kdnuggets.com/2020/03/linear-logistic-regression-explained.html\n",
        "\n",
        "**二元交叉(火商)損失函數視覺分析：**\n",
        "\n",
        "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a\n",
        "\n",
        "**二元交叉(火商)計算器：**\n",
        "\n",
        "https://www.omnicalculator.com/statistics/shannon-entropy\n",
        "\n",
        "**SVM的計算**\n",
        "\n",
        "https://xavierbourretsicotte.github.io/SVM_by_hand.html\n",
        "\n",
        "**Perceptron 感知器**\n",
        "\n",
        "https://mashimo.wordpress.com/2015/06/06/perceptron-an-artificial-neuron/\n",
        "\n",
        "https://www.geeksforgeeks.org/implementation-of-perceptron-algorithm-for-nor-logic-gate-with-2-bit-binary-input/\n",
        "\n",
        "\n",
        "**Ensemble Aggregation**\n",
        "\n",
        "https://www.ycc.idv.tw/ml-course-techniques_4.html\n",
        "\n",
        "**Adaboost 優化 解說**\n",
        "\n",
        "https://blog.paperspace.com/adaboost-optimizer/#:~:text=AdaBoost%20is%20an%20ensemble%20learning,turn%20them%20into%20strong%20ones.\n",
        "\n",
        "**Enron資料分析**\n",
        "\n",
        "https://williamkoehrsen.medium.com/machine-learning-with-python-on-the-enron-dataset-8d71015be26d\n",
        "\n",
        "\n",
        "**信用卡詐騙機器學習分析**\n",
        "\n",
        "https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87\n",
        "\n",
        "\n",
        "**Hierarchical Clustering**\n",
        "\n",
        "https://medium.com/@sametgirgin/hierarchical-clustering-model-in-5-steps-with-python-6c45087d4318\n",
        "\n",
        "https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/\n",
        "\n",
        "**K-Means Clustering:**\n",
        "\n",
        "https://github.com/realpython/materials/blob/master/practical-k-means/practical-k-means-cancer-gene-expression.ipynb\n",
        "\n",
        "https://realpython.com/k-means-clustering-python/\n",
        "\n",
        "**KNN Classification and Imputation**\n",
        "\n",
        "https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n"
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行影像說明服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'text' with confidence 19.94%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "remote_image_url = \"https://attach.setn.com/newsimages/2021/08/24/3285456-PH.jpg\"\n",
    "\n",
    "'''\n",
    "Describe an Image - remote\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行臉部偵測服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Faces - remote =====\n",
      "Faces in the remote image: \n",
      "'Female' of age 28 at location 59, 147, 122, 210\n",
      "'Male' of age 39 at location 195, 93, 255, 153\n",
      "'Male' of age 32 at location 481, 80, 539, 138\n",
      "'Female' of age 23 at location 392, 114, 447, 169\n",
      "'Female' of age 29 at location 110, 152, 162, 204\n",
      "'Female' of age 27 at location 288, 126, 338, 176\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = '35e3f0794e3a44f3b981d7a864f00cfd'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "\n",
    "'''\n",
    "Detect Faces - remote\n",
    "This example detects faces in a remote image, gets their gender and age, \n",
    "and marks them with a bounding box.\n",
    "'''\n",
    "print(\"===== Detect Faces - remote =====\")\n",
    "# Get an image with faces\n",
    "remote_image_url_faces = \"https://img.freepik.com/free-photo/smiley-people-attending-group-therapy-session_23-2148752038.jpg?size=626&ext=jpg&ga=GA1.2.1933447203.1629590400\"\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"faces\"]\n",
    "# Call the API with remote URL and features\n",
    "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
    "\n",
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(detect_faces_results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行影像類別偵測服務操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以REST API方式取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"imageType\": {\"clipArtType\": 0, \"lineDrawingType\": 0}, \"requestId\": \"df30040b-ea5b-43fa-8e6c-5a5e8e176a98\", \"metadata\": {\"height\": 387, \"width\": 666, \"format\": \"Jpeg\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# If you are using a Jupyter notebook, uncomment the following line.\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import json\n",
    "# from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "\n",
    "analyze_url = endpoint + \"vision/v2.1/analyze\"\n",
    "\n",
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = \"https://attach.setn.com/newsimages/2021/08/24/3285456-PH.jpg\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params = {'visualFeatures': 'imageType'}\n",
    "data = {'url': image_url}\n",
    "response = requests.post(analyze_url, headers=headers,\n",
    "                         params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# The 'analysis' object contains various fields that describe the image. The most\n",
    "# relevant caption for the image is obtained from the 'description' property.\n",
    "print(json.dumps(response.json()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

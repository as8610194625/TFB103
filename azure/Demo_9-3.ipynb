{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印刷文字辨識服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n",
      "32207-$ 89 III 658050\n",
      "[638.0, 49.0, 905.0, 48.0, 905.0, 70.0, 638.0, 72.0]\n",
      "$ 160 1-1~1-8 29 -643 ()\n",
      "[647.0, 83.0, 901.0, 83.0, 901.0, 102.0, 647.0, 102.0]\n",
      ":REM . (A)@ (B) (CODE (D)204 .\n",
      "[611.0, 275.0, 931.0, 274.0, 931.0, 290.0, 611.0, 291.0]\n",
      "* (C ) 4 MAJECERAMI$500,000 . ARMISIO . LABROKEN . KIN\n",
      "[532.0, 360.0, 1058.0, 360.0, 1058.0, 378.0, 532.0, 378.0]\n",
      "JU$412.500 . HI KINDRiTHE (A)$10 (B)$15 (C)$25 (D)$30 -\n",
      "[610.0, 400.0, 1043.0, 401.0, 1043.0, 418.0, 610.0, 417.0]\n",
      "(D)CAME . 4. ($412,500-50,000X - X$6) + 12,500+ do $4$10=$25\n",
      "[606.0, 445.0, 1044.0, 445.0, 1044.0, 460.0, 606.0, 461.0]\n",
      "CERNERMAN ORWAS .\n",
      "[607.0, 488.0, 819.0, 488.0, 819.0, 504.0, 607.0, 504.0]\n",
      "(D ) 11.JUR OR$2. 40 . TAMIAMI $24 . NORTE Mi$36 . BUFF\n",
      "[548.0, 725.0, 1058.0, 725.0, 1058.0, 741.0, 548.0, 742.0]\n",
      "ZA MILES? (A)10% (B)1.5 (C)15 (D)10 .\n",
      "[607.0, 745.0, 921.0, 746.0, 921.0, 762.0, 607.0, 761.0]\n",
      "(D ) 12. *ABOUT MOR . Kiwi$10 . 1/1 MinEy) 20,000 8 . 5/1 BIMART\n",
      "[548.0, 769.0, 1059.0, 769.0, 1059.0, 786.0, 548.0, 786.0]\n",
      "9.000 4 . 8/1 BUMPER: 2,400 2 . 10/1 WA) WI1 2 K . DORMI\n",
      "[608.0, 787.0, 1059.0, 788.0, 1059.0, 806.0, 608.0, 805.0]\n",
      "(DOME PERU (A)40,000 X (B)12,000 ' (C)52,000 * (D)50,000 -\n",
      "[607.0, 808.0, 1058.0, 809.0, 1058.0, 827.0, 607.0, 826.0]\n",
      "G 16-1\n",
      "[1000.0, 843.0, 1060.0, 841.0, 1060.0, 858.0, 1001.0, 860.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "'''\n",
    "Batch Read File, recognize printed text - remote\n",
    "This example will extract printed text in an image, then print results, line by line.\n",
    "This API call can also recognize handwriting (not shown).\n",
    "'''\n",
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with printed text\n",
    "remote_image_printed_text_url = \"http://4.bp.blogspot.com/-14jHL5_HYG0/Vht8c5Fw7EI/AAAAAAAABIU/DH2IEv6MNys/s1600/16-1.png\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_printed_results = computervision_client.batch_read_file(remote_image_printed_text_url,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_printed_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_printed_text_results = computervision_client.get_read_operation_result(operation_id)\n",
    "    if get_printed_text_results.status not in ['NotStarted', 'Running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if get_printed_text_results.status == TextOperationStatusCodes.succeeded:\n",
    "    for text_result in get_printed_text_results.recognition_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n",
      "04141 87520 00029 08316 13416 94642 20119\n",
      "[161.0, 709.0, 868.0, 720.0, 867.0, 781.0, 160.0, 770.0]\n",
      "HA HA : 110/08/27Block\n",
      "[361.0, 791.0, 794.0, 806.0, 793.0, 848.0, 359.0, 833.0]\n",
      "HASI : #110000078 # 1 #JJ\n",
      "[306.0, 836.0, 705.0, 841.0, 705.0, 879.0, 306.0, 874.0]\n",
      "1608 10\n",
      "[90.0, 889.0, 331.0, 889.0, 331.0, 926.0, 90.0, 926.0]\n",
      "41 31 32 49\n",
      "[327.0, 889.0, 737.0, 891.0, 737.0, 930.0, 327.0, 928.0]\n",
      "BRIEF$50\n",
      "[806.0, 894.0, 945.0, 896.0, 944.0, 936.0, 806.0, 934.0]\n",
      "2507\n",
      "[83.0, 934.0, 235.0, 930.0, 235.0, 965.0, 84.0, 968.0]\n",
      "17 20 )30 32 46\n",
      "[247.0, 928.0, 740.0, 934.0, 740.0, 972.0, 247.0, 967.0]\n",
      "TEETH NT$ 100\n",
      "[268.0, 989.0, 721.0, 989.0, 721.0, 1023.0, 268.0, 1023.0]\n",
      ": 110/08/26 22:54:52\n",
      "[267.0, 1028.0, 738.0, 1034.0, 738.0, 1071.0, 267.0, 1065.0]\n",
      "MRS : 24044074 KiE : 240440741\n",
      "[229.0, 1068.0, 787.0, 1077.0, 787.0, 1115.0, 228.0, 1106.0]\n",
      "000727079* TR: 0001282289 12944005700145246336\n",
      "[100.0, 1111.0, 893.0, 1123.0, 893.0, 1161.0, 99.0, 1148.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "'''\n",
    "Batch Read File, recognize printed text - remote\n",
    "This example will extract printed text in an image, then print results, line by line.\n",
    "This API call can also recognize handwriting (not shown).\n",
    "'''\n",
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with printed text\n",
    "import os\n",
    "local_image_path = \"C:/Users/Tibame/Desktop/x3.jpg\"\n",
    "\n",
    "# 讀取圖片\n",
    "remote_image_printed_text = open(local_image_path, \"rb\")\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_printed_results = computervision_client.batch_read_file_in_stream(remote_image_printed_text,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_printed_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_printed_text_results = computervision_client.get_read_operation_result(operation_id)\n",
    "    if get_printed_text_results.status not in ['NotStarted', 'Running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if get_printed_text_results.status == TextOperationStatusCodes.succeeded:\n",
    "    for text_result in get_printed_text_results.recognition_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手寫文字辨識服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n",
      "32207-$ 89 III 658050\n",
      "[638.0, 49.0, 905.0, 48.0, 905.0, 70.0, 638.0, 72.0]\n",
      "$ 160 1-1~1-8 29 -643 ()\n",
      "[647.0, 83.0, 901.0, 83.0, 901.0, 102.0, 647.0, 102.0]\n",
      ":REM . (A)@ (B) (CODE (D)204 .\n",
      "[611.0, 275.0, 931.0, 274.0, 931.0, 290.0, 611.0, 291.0]\n",
      "* (C ) 4 MAJOR AMI$500,000 . ARMISIO . LABROKEN . KIN\n",
      "[532.0, 360.0, 1058.0, 360.0, 1058.0, 378.0, 532.0, 378.0]\n",
      "JU$412.500 . JU KINDRiTHE (A)$10 (B)$15 (C)$25 (D)$30 -\n",
      "[610.0, 400.0, 1043.0, 401.0, 1043.0, 418.0, 610.0, 417.0]\n",
      "(D)CAME . 4. ($412,500-50,000X - X$6) + 12,500+ do $4$10=$25\n",
      "[606.0, 445.0, 1044.0, 445.0, 1044.0, 460.0, 606.0, 461.0]\n",
      "CERNERMAN ORWAS .\n",
      "[607.0, 488.0, 819.0, 488.0, 819.0, 504.0, 607.0, 504.0]\n",
      "(D ) 11.JUR OR$2. 40 . TAMIAMI $24 . NORTE Mi$36 . BUFF\n",
      "[548.0, 725.0, 1058.0, 725.0, 1058.0, 741.0, 548.0, 742.0]\n",
      "ZA MILES? (A)10% (B)1.5 (C)15 (D)10 .\n",
      "[607.0, 745.0, 921.0, 746.0, 921.0, 762.0, 607.0, 761.0]\n",
      "(D ) 12. *ABOUT MOR . Kiwi$10 . 1/1 MinEy) 20,000 8 . 5/1 BIMART\n",
      "[548.0, 769.0, 1059.0, 769.0, 1059.0, 786.0, 548.0, 786.0]\n",
      "9.000 4 . 8/1 BUMPER: 2,400 2 . 10/1 WA) WI1 2 K . DORMI\n",
      "[608.0, 787.0, 1059.0, 788.0, 1059.0, 806.0, 608.0, 805.0]\n",
      "(DOME PERU (A)40,000 X (B)12,000 ' (C)52,000 * (D)50,000 -\n",
      "[607.0, 808.0, 1058.0, 809.0, 1058.0, 827.0, 607.0, 826.0]\n",
      "G 16-1\n",
      "[1000.0, 843.0, 1060.0, 841.0, 1060.0, 858.0, 1001.0, 860.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'e9517eef1d664b709b7610da6c009a4d'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103vis.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "'''\n",
    "Batch Read File, recognize printed text - remote\n",
    "This example will extract printed text in an image, then print results, line by line.\n",
    "This API call can also recognize handwriting (not shown).\n",
    "'''\n",
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with printed handwritten\n",
    "remote_image_printed_text_url = \"http://4.bp.blogspot.com/-14jHL5_HYG0/Vht8c5Fw7EI/AAAAAAAABIU/DH2IEv6MNys/s1600/16-1.png\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_printed_results = computervision_client.batch_read_file(remote_image_printed_text_url,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_printed_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_printed_text_results = computervision_client.get_read_operation_result(operation_id)\n",
    "    if get_printed_text_results.status not in ['NotStarted', 'Running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if get_printed_text_results.status == TextOperationStatusCodes.succeeded:\n",
    "    for text_result in get_printed_text_results.recognition_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageEnhance\n",
    "image_file = Image.open(\"C:/Users/Tibame/Desktop/x3.jpg\") # open colour image\n",
    "# image_file = ImageEnhance.Contrast(image_file)\n",
    "image_file = image_file.convert('1') # convert image to black and white\n",
    "\n",
    "image_file.save(\"C:/Users/Tibame/Desktop/xxxxx.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (本地端)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "['08 10 11 31 32']\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "['07 17 20 30 32']\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "[]\n",
      "=======\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from PIL import ImageEnhance\n",
    "import time\n",
    "\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'e9517eef1d664b709b7610da6c009a4d'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103vis.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "'''\n",
    "Batch Read File, recognize printed text - remote\n",
    "This example will extract printed text in an image, then print results, line by line.\n",
    "This API call can also recognize handwriting (not shown).\n",
    "'''\n",
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with printed handwritten\n",
    "import os\n",
    "local_image_path = \"C:/Users/Tibame/Desktop/xxxxx.jpg\"\n",
    "\n",
    "# 讀取圖片\n",
    "remote_image_printed_text = open(local_image_path, \"rb\")\n",
    "\n",
    "# remote_image_printed_text = remote_image_printed_text\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_printed_results = computervision_client.batch_read_file_in_stream(remote_image_printed_text,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_printed_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_printed_text_results = computervision_client.get_read_operation_result(operation_id)\n",
    "    if get_printed_text_results.status not in ['NotStarted', 'Running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "import re\n",
    "# Print the detected text, line by line\n",
    "if get_printed_text_results.status == TextOperationStatusCodes.succeeded:\n",
    "    for text_result in get_printed_text_results.recognition_results:\n",
    "        for line in (text_result.lines):\n",
    "#             print(line.text)\n",
    "            print(\"=======\")\n",
    "            find_pattren = re.compile(r'\\d\\d\\s\\d\\d\\s\\d\\d\\s\\d\\d\\s\\d\\d',re.I)\n",
    "            result = find_pattren.findall(line.text)\n",
    "            print(result)\n",
    "            if resulte\n",
    "            \n",
    "#             print(line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 成人內容偵測服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Adult or Racy Content - remote =====\n",
      "Analyzing remote image for adult or racy content ... \n",
      "Is adult content: True with confidence 95.26\n",
      "Has racy content: True with confidence 98.35\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = '35e3f0794e3a44f3b981d7a864f00cfd'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "remote_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Lot_en_zijn_dochters_Rijksmuseum_SK-A-4866.jpeg/250px-Lot_en_zijn_dochters_Rijksmuseum_SK-A-4866.jpeg\"\n",
    "\n",
    "'''\n",
    "Detect Adult or Racy Content - remote\n",
    "This example detects adult or racy content in a remote image, then prints the adult/racy score.\n",
    "The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n",
    "'''\n",
    "print(\"===== Detect Adult or Racy Content - remote =====\")\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch Read File - remote =====\n",
      "O\n",
      "04141 87520 00029 08316 13416 94642 20119\n",
      "HI : 110/08/27 Brick\n",
      "HASI : #110000078 # 1 #JJ\n",
      "1 08 10 11 31 32 49\n",
      "2507\n",
      "17 20 )30 327 46\n",
      "WE SETH NT$ 100\n",
      ": 110/08/26 22:54:52\n",
      "1RS : 24044074 KiE: 240440741\n",
      "000727079* TR: 0001282289 12944005700145246336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "'''\n",
    "Batch Read File, recognize printed text - remote\n",
    "This example will extract printed text in an image, then print results, line by line.\n",
    "This API call can also recognize handwriting (not shown).\n",
    "'''\n",
    "print(\"===== Batch Read File - remote =====\")\n",
    "# Get an image with printed text\n",
    "import os\n",
    "local_image_path = \"C:/Users/Tibame/Desktop/xxxx.jpg\"\n",
    "\n",
    "# 讀取圖片\n",
    "remote_image_printed_text = open(local_image_path, \"rb\")\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_printed_results = computervision_client.batch_read_file_in_stream(remote_image_printed_text,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_printed_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "# analyze_image_by_domain_in_stream(model, image, language='en', model_version='latest', custom_headers=None, raw=False, callback=None, **operation_config)\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_printed_text_results = computervision_client.get_read_operation_result(operation_id)\n",
    "    if get_printed_text_results.status not in ['NotStarted', 'Running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if get_printed_text_results.status == TextOperationStatusCodes.succeeded:\n",
    "    for text_result in get_printed_text_results.recognition_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "#             print(line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputerVisionErrorException",
     "evalue": "Input data is not a valid image.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComputerVisionErrorException\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-4c73a9763fc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0moperationLocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Operation-Location'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0moperation_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperationLocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputervision_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze_image_in_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_image_printed_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTextOperationStatusCodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msucceeded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mread_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python_azure\\lib\\site-packages\\azure\\cognitiveservices\\vision\\computervision\\operations\\_computer_vision_client_operations.py\u001b[0m in \u001b[0;36manalyze_image_in_stream\u001b[1;34m(self, image, visual_features, details, language, description_exclude, custom_headers, raw, callback, **operation_config)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mComputerVisionErrorException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComputerVisionErrorException\u001b[0m: Input data is not a valid image."
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes,TextOperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "\n",
    "# Set API key.\n",
    "subscription_key = 'b732ee1f895144f5811d5c3a1fe76a9f'\n",
    "\n",
    "# Set endpoint.\n",
    "endpoint = 'https://tfb103.cognitiveservices.azure.com/'\n",
    "# Call API\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "import os\n",
    "local_image_path = \"C:/Users/Tibame/Desktop/xxxx.jpg\"\n",
    "remote_image_printed_text = open(local_image_path, \"rb\")\n",
    "response = computervision_client.batch_read_file_in_stream(remote_image_printed_text,language='en',raw=True)\n",
    "operationLocation = response.headers['Operation-Location']\n",
    "operation_id = operationLocation.split('/')[-1]\n",
    "result = computervision_client.analyze_image_in_stream(remote_image_printed_text,language='en',raw=True)\n",
    "if result.status == TextOperationStatusCodes.succeeded:\n",
    "    read_result = result.analyze_result.read_result\n",
    "    for analyze_result in read_result:\n",
    "        for line in analyze_result.lines:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.cognitiveservices.vision.customvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-93c2d62f3de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustomvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCustomVisionTrainingClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustomvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCustomVisionPredictionClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustomvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageFileCreateBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFileCreateEntry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRegion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmsrest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthentication\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mApiKeyCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muuid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.cognitiveservices.vision.customvision'"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
